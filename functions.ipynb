{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b20ead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elements_occurance(df):\n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "    cols = list(df.columns.values)    #Make a list of all of the columns in the df\n",
    "    set = df.astype(bool).sum(axis=0) # Extract the occurance of each element in the alloys\n",
    "\n",
    "    element_df = set.to_frame()      # Convert extracted the occurance of each element in dataframe\n",
    "\n",
    "    element_occurancy = element_df[7:]\n",
    "    element_occurancy.columns =['Occurance']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f57783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_element_number(df):\n",
    "    # Add a column of \"Number of component\" & \"component\" in each alloy system\n",
    "    prop = []\n",
    "    for number in range(len(df['formula_pretty'])):\n",
    "        mpea = df['composition'][number]\n",
    "        element = list(Composition(mpea).as_dict().keys()) # List element present in Alloys ['Al', 'Cr', 'Fe', 'Ni', 'Mo']\n",
    "        prop.append([len(element), \" \".join(element)])\n",
    "\n",
    "        prop_data = pd.DataFrame(prop, columns=['No of Components', 'Component'])\n",
    "    df = pd.concat([df, prop_data], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bdc5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_number(df, fig_title='Elements Number', fig_name='element_number'):\n",
    "    import os\n",
    "    import matplotlib\n",
    "    import matplotlib.ticker as tck\n",
    "    import seaborn as sns\n",
    "    #matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(5,5))\n",
    "    ax = sns.countplot(x='No of Components', data=df)\n",
    "    \n",
    "    plt.rcParams.update({'font.size': 20})\n",
    "    \n",
    "    ax.set_title('Number of elements', fontdict={'size': 24, 'color': 'blue'})\n",
    "    #ax.bar_label(ax.containers[0], fontproperties={'size': 18})\n",
    "        \n",
    "    ax.set_xlabel('Element Numbers', fontdict={'size': 20, 'color': 'r'})\n",
    "    ax.set_ylabel('Count', fontdict={'size': 20, 'color': 'r'})\n",
    "    \n",
    "    plt.ylim(0, 820,400)\n",
    "    \n",
    "    plt.tick_params(axis='both', which='both', length=5, width=1.5,color='black')\n",
    "    \n",
    "    ax.yaxis.set_minor_locator(tck.AutoMinorLocator(2))\n",
    "    \n",
    "    plt.savefig(\"plots//element_number\",dpi=1200, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab653c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_occurrence(df,limit_value=8, fig_title='Hardness/ Elongation', fig_name='element_occurrence'):\n",
    "    \n",
    "    df = df.loc[:, (df != 0).any(axis=0)]\n",
    "\n",
    "    cols = list(df.columns.values)    #Make a list of all of the columns in the df\n",
    "    set = df.astype(bool).sum(axis=0) # Extract the occurance of each element in the alloys\n",
    "\n",
    "    element_df = set.to_frame()      # Convert extracted the occurance of each element in dataframe\n",
    "\n",
    "    element_occurancy = element_df[limit_value:-150]\n",
    "    element_occurancy.columns =['Occurrence']\n",
    "    element_occurancy = element_occurancy.sort_values('Occurrence')\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(36,20))\n",
    "    \n",
    "    df = element_occurancy\n",
    "    print(df)\n",
    "    \n",
    "    mask = df['Occurrence'] <= 29\n",
    "    df1 = df[mask]\n",
    "    df2_3 = df[~mask]\n",
    "    \n",
    "    mask2 = df2_3['Occurrence'] < 75\n",
    "    df2 = df2_3[mask2]\n",
    "    df3 = df2_3[~mask2]\n",
    "    \n",
    "    import matplotlib\n",
    "    #matplotlib.use('agg')\n",
    "    def plot_hor_bar(subplot, data, title = 'title', xlabel = 'Occurrence'):\n",
    "        print('lenght:  ',len(data))\n",
    "        plt.subplot(1,3,subplot)\n",
    "        ax = sns.barplot(x=data['Occurrence'],y=data.index, data=data)\n",
    "        #ax.bar_label(ax.containers[0], fontproperties={'size': 24})\n",
    "        plt.title(title,\n",
    "                  fontsize=36, color='b')\n",
    "        plt.xlabel(xlabel, fontsize=42, color='b')\n",
    "        plt.xticks(fontsize=36)\n",
    "        ax.xaxis.set_major_locator(plt.MaxNLocator(6))\n",
    "        \n",
    "        plt.ylabel(None)\n",
    "        plt.yticks(fontsize=40,color='black')\n",
    "        plt.tick_params(axis='both', which='both', length=15, width=5,color='black')\n",
    "        #plt.pause(.01)\n",
    "        sns.despine(left=True)\n",
    "        ax.grid(False)\n",
    "        ax.tick_params(bottom=True, left=False)\n",
    "\n",
    "        return None\n",
    " \n",
    "    \n",
    "    plot_hor_bar(1, df1, title = 'Elements Occurring Less than 25', xlabel = ' ')\n",
    "    plot_hor_bar(2, df2, title = 'Elements Occurring from 25 to 75', xlabel = 'Occurrence counts')\n",
    "    plot_hor_bar(3, df3, title = 'Elements Occurring more than 75', xlabel = ' ')\n",
    "    #plt.title('Elements Occurrence counts')\n",
    "    \n",
    "    plt.savefig(\"plots//element_occurrence\",dpi=200, bbox_inches='tight')\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a95a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def properties_calculation(dataframe):\n",
    "    \n",
    "    # Import csv files \"Midema\" to calculte input features\n",
    "    elem_prop_data = pd.read_csv('csv/Miedema.csv')\n",
    "    VEC_elements = elem_prop_data.set_index('element')['valence_electrons'].to_dict()\n",
    "    shear_modulus_g = elem_prop_data.set_index('element')['shear_modulus'].to_dict()\n",
    "    bulk_modulus_b = elem_prop_data.set_index('element')['compressibility'].to_dict()\n",
    "    \n",
    "    # Input featurs calculation\n",
    "    df = dataframe\n",
    "    properties = []\n",
    "    for number in range(len(df['formula_pretty'])):\n",
    "\n",
    "        mpea = df['composition'][number]\n",
    "        #print(mpea)\n",
    "        #print(Composition(mpea).as_dict().keys())\n",
    "        element = list(Composition(mpea).as_dict().keys()) # List element present in Alloys ['Al', 'Cr', 'Fe', 'Ni', 'Mo']\n",
    "        #print(element)\n",
    "        fraction_composition = list(Composition(mpea).as_dict().values()) # List Fraction composition of corresponding element in an Alloy eg. [1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "        #print(fraction_composition)\n",
    "        total_mole = sum(fraction_composition) # Sum of elemental composition\n",
    "        #print(total_mole)\n",
    "\n",
    "        atomic_number = []\n",
    "        bulk_modulus = []\n",
    "        shear_modulus = []\n",
    "        molar_heat = []\n",
    "        thermal_conductivity = []\n",
    "        mole_fraction = []\n",
    "        X_i = []\n",
    "        r_i = []\n",
    "        Tm_i = []\n",
    "        VEC_i= []\n",
    "        R = 8.314\n",
    "\n",
    "        for i in element:\n",
    "\n",
    "            atomic_number.append(Element(i).Z)\n",
    "            #molar_heat.append(Cp_dict[i])\n",
    "\n",
    "            bulk_b =Element(i).bulk_modulus\n",
    "\n",
    "            if type(bulk_b) == type(None):\n",
    "                for j in bulk_modulus_b: bulk_b = (bulk_modulus_b.get(j))       \n",
    "\n",
    "            bulk_modulus.append(bulk_b)\n",
    "\n",
    "            #print(bulk_modulus)\n",
    "\n",
    "            shear_g = (Element(i).rigidity_modulus)\n",
    "            if type(shear_g) == type(None):\n",
    "                for s in shear_modulus_g: shear_g = ((shear_modulus_g.get(s)))\n",
    "            shear_modulus.append(shear_g)\n",
    "\n",
    "            thermal_conductivity.append(Element(i).thermal_conductivity)\n",
    "            mole_fraction.append(Composition(mpea).get_atomic_fraction(i)) # Calculates mole fraction of mpea using \"Composition\" functions\n",
    "\n",
    "            X_i.append(Element(i).X) # Calculate individual electronegativity using \"Element\" function\n",
    "\n",
    "            r_i.append(Element(i).atomic_radius) if Element(i).atomic_radius_calculated == None else r_i.append(Element(i).atomic_radius_calculated) # There are two functions present in Element␣class of pymatgen, so here checking using if conditional in both functions␣to not miss any value\n",
    "            Tm_i.append(Element(i).melting_point) # Calculating melting point of every element using \"Element\" class and function\n",
    "            \n",
    "            try: VEC_i.append(DemlData().get_elemental_property(Element(i),\"valence\")) # VEC is also present in 2 locations in matminer, first is the␣function \"DemlData()\"\n",
    "            except KeyError:\n",
    "                if i in VEC_elements: VEC_i.append(float(VEC_elements.get(i))) #In case data is not present in \"DemlData()\" function, there is a csv file␣inside matminer opened earlier as \"elem_prop_data\" in the very first cell\n",
    "                if i=='Xe': VEC_i.append(float(2))\n",
    "            #print(number, VEC_i)\n",
    "            #print('VEC: ',i, VEC_elements.get('Xe'))\n",
    "        \n",
    "        # Average Atomic Number\n",
    "        AN = sum(np.multiply(mole_fraction, atomic_number))\n",
    "        #print(AN)\n",
    "\n",
    "        # Average Molar Heat coefficient\n",
    "        #Cp_bar = sum(np.multiply(mole_fraction, molar_heat))    \n",
    "        #print(Cp_bar)\n",
    "\n",
    "        #term_Cp = (1-np.divide(molar_heat, Cp_bar))**2\n",
    "        #del_Cp = sum(np.multiply(mole_fraction, term_Cp))**0.5 \n",
    "\n",
    "        # Thermal Conductivity\n",
    "        k = sum(np.multiply(mole_fraction, thermal_conductivity))\n",
    "\n",
    "        # Bulk Modolus\n",
    "        bulk = sum(np.multiply(mole_fraction, bulk_modulus)) # Bulk modulus of 'Zr' not present\n",
    "        \n",
    "        # Bulk modolus asymmetry\n",
    "        term_bulk = (1-np.divide(bulk_modulus, bulk))**2\n",
    "        del_bulk = sum(np.multiply(mole_fraction, term_bulk))**0.5         \n",
    "\n",
    "        # Shear Modolus\n",
    "        shear= sum(np.multiply(mole_fraction, shear_modulus))\n",
    "        \n",
    "        # Shear modolus asymmetry\n",
    "        term_shear = (1-np.divide(shear_modulus, shear))**2\n",
    "        del_shear = sum(np.multiply(mole_fraction, term_shear))**0.5         \n",
    "\n",
    "        # Calculation of Atomic Radius Difference (del)\n",
    "\n",
    "        r_bar = sum(np.multiply(mole_fraction, r_i))\n",
    "        term = (1-np.divide(r_i, r_bar))**2\n",
    "        atomic_size_difference = sum(np.multiply(mole_fraction, term))**0.5 \n",
    "        #print(number,element,mole_fraction,r_i,r_bar,term,atomic_size_difference)\n",
    "\n",
    "\n",
    "        # Electronegativity (del_X)\n",
    "        X_bar = sum(np.multiply(mole_fraction, X_i))\n",
    "        del_Chi = (sum(np.multiply(mole_fraction, (np.subtract(X_i,X_bar))**2)))**0.5\n",
    "        #term_X = (1-np.divide(X_i, X_bar))**2\n",
    "        #del_Chi = (sum(np.multiply(mole_fraction, term_X)))**0.5 \n",
    "\n",
    "        # Difference Melting Temperature\n",
    "        T_bar = sum(np.multiply(mole_fraction, Tm_i))\n",
    "        del_Tm =(sum(np.multiply(mole_fraction, (np.subtract(Tm_i,T_bar))**2)))**0.5\n",
    "\n",
    "        # Average Melting Temperature\n",
    "        Tm = sum(np.multiply(mole_fraction, Tm_i))    \n",
    "\n",
    "        # Valence Electron Concentration\n",
    "        #print(mole_fraction.shape, VEC_i.shape)\n",
    "        #print(number)\n",
    "        #print(mole_fraction)\n",
    "        #print(VEC_i)\n",
    "        VEC = sum(np.multiply(mole_fraction, VEC_i))\n",
    "        #print(VEC)\n",
    "\n",
    "        # Entropy of mixing\n",
    "        #del_Smix = -WenAlloys().compute_configuration_entropy(mole_fraction)*1000 #WenAlloys class imported from matminer library\n",
    "        del_Smix = -R*sum(np.multiply(mole_fraction, np.log(mole_fraction)))\n",
    "\n",
    "\n",
    "        HEA = element\n",
    "        #print(len(mole_fraction), len(HEA))\n",
    "\n",
    "\n",
    "        # Enthalpy of mixing\n",
    "        AB = []\n",
    "        C_i_C_j = []\n",
    "        del_Hab = []\n",
    "        for item in range(len(HEA)):\n",
    "            for jitem in range(item, len(HEA)-1):\n",
    "                AB.append(HEA[item] + HEA[jitem+1])\n",
    "                C_i_C_j.append(mole_fraction[item]*mole_fraction[jitem+1])\n",
    "                #del_Hab.append(round(Miedema().deltaH_chem([HEA[item], HEA[jitem+1]], [0.5, 0.5], 'ss'),3)) # Calculating binary entropy of mixing at 0.5-0.5␣ (equal) composition using Miedema class of \"matminer\" library\n",
    "                del_Hab.append(MixingEnthalpy().get_mixing_enthalpy(Element(HEA[item]), Element(HEA[jitem+1]))) # Matminer MixingOfEnthalpy\n",
    "                #print(HEA)\n",
    "                #print(del_Hab)\n",
    "                #print(\" \")\n",
    "\n",
    "        omega = np.multiply(del_Hab, 4)\n",
    "        del_Hmix = sum(np.multiply(omega, C_i_C_j))\n",
    "\n",
    "        # Geometrical parameters\n",
    "        if atomic_size_difference == 0:  atomic_size_difference = 1e-9\n",
    "        lemda = np.divide(del_Smix, (atomic_size_difference)**2)\n",
    "        #print(number,del_Smix,atomic_size_difference, lemda)\n",
    "\n",
    "        #parameter = Tm*del_Smix/abs(del_Hmix) \n",
    "        #print(number,\"lemda, parameter\", lemda, parameter)\n",
    "\n",
    "\n",
    "        #properties.append([len(element), \" \".join(element), \" \".join(list(map(str, fraction_composition))),total_mole, round(sum(mole_fraction),1), atomic_size_difference, round(del_Chi, 4),del_Tm, Tm, VEC, AN, k, bulk,del_bulk,shear,del_shear, round(del_Smix, 4),round(lemda,4), round(del_Hmix, 4),round(parameter,4)])\n",
    "        properties.append([len(element), \" \".join(element), \" \".join(list(map(str, fraction_composition))),total_mole, round(sum(mole_fraction),1), atomic_size_difference, round(del_Chi, 4),del_Tm, Tm, VEC, AN, k, bulk,del_bulk,shear,del_shear, round(del_Smix, 4),round(lemda,4)])\n",
    "    #prop_data = pd.DataFrame(properties, columns=['No of Components','Component','Moles of individual Components', 'Total Moles', 'Sum of individual MoleFractions', '$\\delta$', 'Δ$\\chi$', 'ΔTm','Tm(K)', 'VEC', 'AN', 'K','B', 'ΔB','G', 'ΔG','ΔSmix','$\\lambda$', 'ΔHmix','$\\Omega$'])\n",
    "    prop_data = pd.DataFrame(properties, columns=['No of Components','Component','Moles of individual Components', 'Total Moles', 'Sum of individual MoleFractions', '$\\delta$', 'Δ$\\chi$', 'ΔTm','Tm(K)', 'VEC', 'AN', 'K','B', 'ΔB','G', 'ΔG', 'ΔSmix','$\\lambda$',])\n",
    "\n",
    "    df = pd.concat([df, prop_data], axis = 1)\n",
    "    \n",
    "    df_input_target = df.iloc[:,[-18,-13,-12,-11,-10, -9, -8, -7, -6,-5, -4, -3, -2, -1,4,5,2,6,7]]\n",
    "    \n",
    "    return(df,df_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_target(datasets, input_name):\n",
    "    inputs = datasets\n",
    "    inputs = inputs.astype(float)\n",
    "\n",
    "#     print(inputs.head(2))\n",
    "#     print(\"..................................\")\n",
    "    #df_all = pd.DataFrame(inputs, columns = input_name+[\"e_ij_max\"])\n",
    "    #print(df_all.head())\n",
    "\n",
    "    df_inputs = df_all.drop(['e_ij_max'], axis=1)\n",
    "    df_targets = df_all['e_ij_max']\n",
    "    return (df_all, df_inputs, df_targets)\n",
    "    \n",
    "def train_test_split(datasets, input_name):\n",
    "    \n",
    "    #df_all = datasets.astype(float)\n",
    "    df_all = datasets\n",
    "    df_inputs = df_all.drop(['e_ij_max','total'], axis=1)\n",
    "    df_targets = df_all['total']\n",
    "    \n",
    "\n",
    "\n",
    "    # Split dataset in train-test\n",
    "#     print(\"..................................\")\n",
    "#     print(df_all.head(2))\n",
    "#     print(\"..................................\")\n",
    "#     print(df_inputs.head(2))\n",
    "#     print(\"..................................\")\n",
    "#     print(df_targets.head())\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_inputs, df_targets, test_size=0.1, random_state=33)\n",
    "\n",
    "    #X_train, X_test,  = train_test_split(df_inputs, test_size=0.1, random_state=0)\n",
    "\n",
    "    #X_train_no_fab = X_train.drop(['Fab_1', 'Fab_2', 'Fab_3', 'Fab_4','No of Components'], axis=1)\n",
    "    #X_train_fab = X_train.loc[:,['Fab_1', 'Fab_2', 'Fab_3', 'Fab_4']]\n",
    "\n",
    "    #X_test_no_fab = X_test.drop(['Fab_1', 'Fab_2', 'Fab_3', 'Fab_4','No of Components'], axis=1)\n",
    "    #X_test_fab = X_test.loc[:,['Fab_1', 'Fab_2', 'Fab_3', 'Fab_4']]\n",
    "    \n",
    "    ##n_component = X_train.loc[:,['No of Components']]\n",
    "\n",
    "    input_df = pd.concat([X_train, y_train], axis=1)\n",
    "    \n",
    "    y_train = y_train.reset_index(drop=True)\n",
    "    y_test = y_test.reset_index(drop=True)\n",
    "    \n",
    "        \n",
    "    X_train = X_train.reset_index(drop=True)\n",
    "    X_test = X_test.reset_index(drop=True)\n",
    "    \n",
    "    return(X_train, X_test,y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb69d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_distrubition(df,title=\"123\"):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    from matplotlib.cm import ScalarMappable\n",
    "    import matplotlib.ticker as tck\n",
    "\n",
    "    df= df.to_frame()\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    plt.rc('font', size=18)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    df[\"total\"] = [np.array(m).astype('float64') for m in df[\"total\"]]\n",
    "\n",
    "    # create plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # create colormap\n",
    "    norm = plt.Normalize(np.array(df[\"total\"].values.tolist()).min(), np.array(df[\"total\"].values.tolist()).max())\n",
    "    cmap = plt.cm.plasma\n",
    "\n",
    "    mappable = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "\n",
    "    # plot surface\n",
    "    for i, row in df.iterrows():\n",
    "        x, y = np.meshgrid(range(6), range(3))\n",
    "        z = row[\"total\"]\n",
    "\n",
    "        #ax.plot_surface(x+i*6, y, z, cmap=cmap, alpha=0.9,linewidth=0, rstride=1, cstride=1)\n",
    "        ax.plot_surface(x, y+i*3, z, cmap=cmap, alpha=0.9,linewidth=0, rstride=1, cstride=1)\n",
    "\n",
    "    # add colorbar\n",
    "    clb = fig.colorbar(mappable, ax=ax,  shrink=0.45, pad = -0.05)\n",
    "    clb.ax.tick_params(labelsize=16) \n",
    "    clb.set_label(r'$\\alpha$', rotation=0)\n",
    "    # Label and coordinate\n",
    "    #ax.text(5, 10,10 , r\"$\\alpha$\", color='red', fontsize=12)\n",
    "    ax.text(4, max(ax.get_ybound()),1.1*max(ax.get_zbound()), r\"$\\alpha ^{  n}_{ij}$\", color='red', fontsize=18)\n",
    "    \n",
    "\n",
    "    # set labels and title\n",
    "    ax.set_xlabel('Columns', labelpad=12, fontsize=20,color='r')\n",
    "    ax.set_ylabel('Rows x N', labelpad=20, fontsize=20,color='r')\n",
    "    #ax.set_zlabel('Frequency', labelpad=8, fontsize=20,color='r')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.set_xticks(np.linspace(0, 6, 4))\n",
    "    #ax.set_xticklabels(['1', '2', '6','2'])\n",
    "\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(4))\n",
    "    ax.xaxis.set_minor_locator(tck.AutoMinorLocator(2))\n",
    "\n",
    "    \n",
    "    ax.zaxis.set_major_locator(MaxNLocator(1))\n",
    "    ax.get_zaxis().set_visible(False)\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=18)\n",
    "    #ax.set_zticklabels(ax.get_zticklabels(), fontsize=18)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "    # set camera angle and distance\n",
    "    #ax.view_init(elev=20, azim=-40)\n",
    "    ax.view_init(elev=20, azim=-40)\n",
    "    #ax.dist=12\n",
    "\n",
    "    # set background color and grid\n",
    "    ax.xaxis.pane.fill = False\n",
    "    ax.yaxis.pane.fill = False\n",
    "    ax.zaxis.pane.fill = False\n",
    "    ax.xaxis.pane.set_edgecolor('white')\n",
    "    ax.yaxis.pane.set_edgecolor('white')\n",
    "    ax.zaxis.pane.set_edgecolor('white')\n",
    "    ax.grid(False)\n",
    "    \n",
    "    ax.set_zticks([]) # Remove the tick labels on the z-axis\n",
    "    ax.set_zticklabels([])\n",
    "\n",
    "    ax.zaxis.line.set_color((1.0, 1.0, 1.0, 0.0)) # Set the z-axis line color to transparent\n",
    "\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7479b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_split(df,title=\"123\"):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    from matplotlib.cm import ScalarMappable\n",
    "\n",
    "    df= df.to_frame()\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    plt.rc('font', size=18)\n",
    "\n",
    "    df[\"total\"] = [np.array(m).astype('float64') for m in df[\"total\"]]\n",
    "\n",
    "    # create plot\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # create colormap\n",
    "    norm = plt.Normalize(np.array(df[\"total\"].values.tolist()).min(), np.array(df[\"total\"].values.tolist()).max())\n",
    "    cmap = plt.cm.plasma\n",
    "\n",
    "    # create ScalarMappable object based on frequency values\n",
    "    sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array(df[\"total\"])\n",
    "\n",
    "    # plot surface with colors based on frequency values\n",
    "    for i, row in df.iterrows():\n",
    "        x, y = np.meshgrid(range(6), range(3))\n",
    "        z = row[\"total\"]\n",
    "\n",
    "        ax.plot_surface(x, y+i*3, z, cmap=cmap, alpha=0.9, linewidth=0, rstride=1, cstride=1)\n",
    "\n",
    "    # add colorbar\n",
    "    fig.colorbar(sm, ax=ax, shrink=0.4, pad=0.04)\n",
    "\n",
    "    # set labels and title\n",
    "    ax.set_xlabel('j x n', labelpad=12, fontsize=20,color='r')\n",
    "    ax.set_ylabel('Rows', labelpad=20, fontsize=20,color='r')\n",
    "    ax.set_zlabel('Frequency', labelpad=8, fontsize=20,color='r')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(6))\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(3))\n",
    "    ax.zaxis.set_major_locator(MaxNLocator(3))\n",
    "\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "    # set camera angle and distance\n",
    "    ax.view_init(elev=15, azim=-30)\n",
    "\n",
    "    # set background color and grid\n",
    "    ax.xaxis.pane.fill = False\n",
    "    ax.yaxis.pane.fill = False\n",
    "    ax.zaxis.pane.fill = False\n",
    "    ax.xaxis.pane.set_edgecolor('white')\n",
    "    ax.yaxis.pane.set_edgecolor('white')\n",
    "    ax.zaxis.pane.set_edgecolor('white')\n",
    "    ax.grid(False)\n",
    "\n",
    "    # set plot size and scale\n",
    "    fig.set_size_inches(10, 8)\n",
    "    x_scale = 0.8\n",
    "    y_scale = 1.2\n",
    "    z_scale = 0.8\n",
    "    scale = np.diag([x_scale, y_scale, z_scale, 1.0])\n",
    "    scale = scale * (1.0/scale.max())\n",
    "    scale[3,3] = 1.0\n",
    "\n",
    "    def short_proj():\n",
    "        return np.dot(Axes3D.get_proj(ax), scale)\n",
    "\n",
    "    ax.get_proj = short_proj\n",
    "\n",
    "    # show plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e1200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n18_split(df,title=\"123\"):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    from matplotlib.ticker import MaxNLocator\n",
    "    from matplotlib.cm import ScalarMappable\n",
    "\n",
    "    df= df.to_frame()\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    plt.rc('font', size=18)\n",
    "\n",
    "    df[\"total\"] = [np.array(m).astype('float64') for m in df[\"total\"]]\n",
    "\n",
    "    # create plot\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # create colormap\n",
    "    norm = plt.Normalize(np.array(df[\"total\"].values.tolist()).min(), np.array(df[\"total\"].values.tolist()).max())\n",
    "    cmap = plt.cm.plasma\n",
    "\n",
    "    # create ScalarMappable object based on frequency values\n",
    "    sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array(df[\"total\"])\n",
    "\n",
    "    # plot surface with colors based on frequency values\n",
    "    for i, row in df.iterrows():\n",
    "        x, y = np.meshgrid(range(18), range(2520))\n",
    "        z = row[\"total\"]\n",
    "\n",
    "        ax.plot_surface(x, y, z, cmap=cmap, alpha=0.9, linewidth=0, rstride=1, cstride=1)\n",
    "\n",
    "    # add colorbar\n",
    "    fig.colorbar(sm, ax=ax, shrink=0.4, pad=0.04)\n",
    "\n",
    "    # set labels and title\n",
    "    ax.set_xlabel('j x n', labelpad=12, fontsize=20,color='r')\n",
    "    ax.set_ylabel('Rows', labelpad=20, fontsize=20,color='r')\n",
    "    ax.set_zlabel('Frequency', labelpad=8, fontsize=20,color='r')\n",
    "    ax.set_title(title)\n",
    "\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(6))\n",
    "    ax.xaxis.set_major_locator(MaxNLocator(3))\n",
    "    ax.zaxis.set_major_locator(MaxNLocator(3))\n",
    "\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=18)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "\n",
    "    # set camera angle and distance\n",
    "    ax.view_init(elev=15, azim=-30)\n",
    "\n",
    "    # set background color and grid\n",
    "    ax.xaxis.pane.fill = False\n",
    "    ax.yaxis.pane.fill = False\n",
    "    ax.zaxis.pane.fill = False\n",
    "    ax.xaxis.pane.set_edgecolor('white')\n",
    "    ax.yaxis.pane.set_edgecolor('white')\n",
    "    ax.zaxis.pane.set_edgecolor('white')\n",
    "    ax.grid(False)\n",
    "\n",
    "    # set plot size and scale\n",
    "    fig.set_size_inches(10, 8)\n",
    "    x_scale = 0.8\n",
    "    y_scale = 1.2\n",
    "    z_scale = 0.8\n",
    "    scale = np.diag([x_scale, y_scale, z_scale, 1.0])\n",
    "    scale = scale * (1.0/scale.max())\n",
    "    scale[3,3] = 1.0\n",
    "\n",
    "    def short_proj():\n",
    "        return np.dot(Axes3D.get_proj(ax), scale)\n",
    "\n",
    "    ax.get_proj = short_proj\n",
    "\n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8e9bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_distribution(data,text,test_annotate=0,test_annotate2=0,limit=1200,distance=0.15,ylabel = 'Hardness (HV)', title=\"Hardness Distribution\",plot_path=\"plots\\\\hardness\\\\\"):\n",
    "    \n",
    "    import seaborn as sns\n",
    "    import matplotlib.ticker as tck\n",
    "    \n",
    "    mean=data.mean()\n",
    "    median=np.median(data)\n",
    "    ten_per = np.percentile(data, 10)\n",
    "    ninety_per = np.percentile(data, 90)\n",
    "    print(text,'\\n Mean: ',mean,'\\n Median: ',median, '\\n 10 Percentile:',ten_per, '\\n 90 Percentile:', ninety_per)\n",
    "    print(\"Number of \",text, data.shape[0])\n",
    "    print(\"----------------------\")\n",
    "    sns.set(style=\"ticks\", color_codes=True,font_scale=1)\n",
    "    \n",
    "    fig , ax = plt.subplots(figsize=(4,4), dpi=400)\n",
    "    sns.kdeplot( y=data, color=\"g\",lw=0.5, shade=True, bw_adjust=1)\n",
    "    \n",
    "    # Plot Mean and Median\n",
    "    plt.plot(distance,mean, marker=\"o\", markersize=6, markeredgecolor=\"red\", markerfacecolor=\"red\", label=\"Mean\",linestyle = 'None')\n",
    "    plt.plot(distance,median, marker=\"^\", markersize=6, markeredgecolor=\"blue\", markerfacecolor=\"blue\", label=\"Median\",linestyle = 'None')\n",
    "    \n",
    "    # Plot 10 and 90 percentile\n",
    "    plt.plot(distance,ten_per, marker=\"o\", markersize=5, markeredgecolor=\"red\", label=\"10% Percentile\",linestyle = 'None')\n",
    "    plt.plot(distance,ninety_per, marker=\"o\", markersize=5, markeredgecolor=\"blue\", label=\"90% Percentile\",linestyle = 'None')\n",
    "\n",
    "    x_values = [distance, distance]\n",
    "    y_values = [ten_per, ninety_per]\n",
    "    plt.plot(x_values, y_values, 'green', linestyle=\"-\")\n",
    "    \n",
    "    # Annotations\n",
    "    plt.text(distance*1.06, ten_per+test_annotate, str(round(ten_per,3))+ \"(10%)\", horizontalalignment='left', size='medium', color='b')\n",
    "    plt.text(distance*1.06, ninety_per+test_annotate2, str(round(ninety_per,3))+ \"(90%)\", horizontalalignment='left', size='medium', color='b')\n",
    "\n",
    "    #plt.gca().axes.get_xaxis().set_visible(False) # Remove x-axis lable\n",
    "    \n",
    "    plt.ylim(0, limit)\n",
    "    ax.yaxis.set_minor_locator(tck.AutoMinorLocator(2))\n",
    "    \n",
    "    plt.title(title+str(text)+\" (\"+str(data.shape[0])+\" data)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    # Crop shaded region above max and below min value\n",
    "    plt.axhspan(0,min(data), color='white')\n",
    "    plt.axhspan(max(data),limit, color='white')\n",
    "\n",
    "    plt.legend(frameon=False,loc='upper right')\n",
    "    plt.savefig(plot_path+str(text)+ylabel+'_split.png',dpi=1200, bbox_inches='tight')\n",
    "    #plt.legend(frameon=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b37d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_data(X_train):\n",
    "    # Standarize the input features\n",
    "    from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "\n",
    "    std_X_train = scaler.fit_transform(X_train)\n",
    "    input_name = list(X_train.columns.values)\n",
    "\n",
    "    std_df = pd.DataFrame(data=std_X_train, columns=input_name)\n",
    "    #std_df['Hardness (HV)'] = y_train\n",
    "    \n",
    "    return(scaler, std_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a9fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(std_train_df,name,prop='e_ij_max'):\n",
    "    import seaborn as sns\n",
    "    sns.set(style=\"ticks\", color_codes=True,font_scale=2.2)\n",
    "    plt.figure(figsize=(22,12))\n",
    "    cmap = sns.diverging_palette(133,10,s=80, l=55, n=9, as_cmap=True)\n",
    "    cor_train = std_train_df.corr()\n",
    "    sns.heatmap(cor_train, annot=True, fmt='.2f',cmap=cmap) #\n",
    "\n",
    "    plt.savefig(name+'_pcc_all.pdf',dpi=1200)\n",
    "    plt.show()\n",
    "\n",
    "def pcc_fs(std_df,y_train,input_pcc,name,prop='HV'):\n",
    "    \n",
    "    std_all_feature = np.column_stack((std_df,y_train))\n",
    "    std_train_df=pd.DataFrame(data=std_all_feature, columns=input_name+[prop])\n",
    "    heatmap(std_train_df,name)\n",
    "    \n",
    "    X_train_pcc = std_train_df.loc[:,input_pcc+[prop]]\n",
    "    import seaborn as sns\n",
    "    plt.figure(figsize=(13,6))\n",
    "    cor_mid = X_train_pcc.corr()\n",
    "    sns.heatmap(cor_mid, annot=True, cmap= plt.cm.CMRmap_r,fmt='.2f')\n",
    "    plt.savefig(name+'_pcc_fs.png',dpi=1200,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3d84bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vif_value(datasets):\n",
    "    from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "    vif = pd.DataFrame()\n",
    "    vif['VIF Factor'] = [variance_inflation_factor(datasets.values,i) for i in range(datasets.shape[1])]\n",
    "\n",
    "    vif['features'] = datasets.columns\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_fs(std_df,name, title=\"a) Hardness PCA-1\"):\n",
    "    \n",
    "    import seaborn as sns\n",
    "    import matplotlib.ticker as tck\n",
    "    \n",
    "    # Plot PCA graph\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA()\n",
    "    sns.set(style=\"ticks\", color_codes=True,font_scale=3)\n",
    "    principalComponents = pca.fit_transform(std_df)\n",
    "    plt.figure(figsize=(8,7))\n",
    "    #plt.figure()\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_),color='purple', linewidth=3)\n",
    "    plt.xlabel('No. of Principal Components')\n",
    "    plt.ylabel('Cumulative EV')\n",
    "    plt.title(title+ ' : Explained Variance ',color='blue', pad=20)\n",
    "    \n",
    "    plt.grid(alpha=0.75)\n",
    "    plt.grid(True, which='minor')\n",
    "\n",
    "    #x=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "    #x=[2,4,6,8,10,12,14]\n",
    "    plt.xlim(0, 150)\n",
    "    #values = range(len(x))\n",
    "    #plt.xticks(values, x)\n",
    "    #plt.xticks()\n",
    "    \n",
    "    # Number of x ticks\n",
    "    plt.xticks(range(0,152,50),rotation=0)\n",
    "    plt.gca().xaxis.set_minor_locator(tck.AutoMinorLocator(2))\n",
    "    #plt.gca().xaxis.set_minor_locator(MultipleLocator(12))\n",
    "    \n",
    "\n",
    "    plt.rcParams.update({'font.size': 30})\n",
    "    plt.tick_params(axis='both', which='both', length=3, width=1,color='black')\n",
    "    \n",
    "    import numpy\n",
    "    plt.yticks(numpy.linspace(0.4, 1.0, num=4))\n",
    "    \n",
    "    plt.ylim(0.2, 1.05)\n",
    "    #plt.yticks(range(0.3,0.9,0.3),rotation=0)\n",
    "    plt.gca().yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "    sns.set(style=\"ticks\", color_codes=True,font_scale=2)\n",
    "\n",
    "    plt.savefig(name+'_fs.png',dpi=1200,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Principal components to capture 0.9 variance in data\n",
    "    pca_1 = PCA(0.96)\n",
    "    df_pca = pca_1.fit_transform(std_df)\n",
    "    \n",
    "    comp = pca_1.n_components_\n",
    "    print('No. of components for PCA:' ,comp)\n",
    "    \n",
    "    pca_new = PCA(n_components = comp)\n",
    "    df_pca_new = pca_new.fit_transform(std_df)\n",
    "    \n",
    "    print('Explained variance for 96% ', comp, 'components: ',pca_new.explained_variance_ratio_)\n",
    "    print('Cumulative:', np.cumsum(pca_new.explained_variance_ratio_))\n",
    "    \n",
    "    return(pca_1,df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c963b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bca3c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e38ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2667a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning Model\n",
    "\n",
    "\n",
    "\n",
    "# The value used in the function plays no role as the different hyperparameter value will be used while calling \"create_model\" function\n",
    "def create_model(lyrs=6, neuron_size=64, act='selu', opt='Adam', dr=0.0, learning_rate=0.001,init_weights= 'he_uniform', weight_constraint = 3):\n",
    "    import tensorflow as tf\n",
    "\n",
    "    import keras\n",
    "    from keras.layers import Dense\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dropout\n",
    "    from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # clear model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    # create first hidden layer\n",
    "    model.add(Dense(neuron_size,input_dim=input_dim, activation=act))\n",
    "    model.add(Dropout(dr))\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # create additional hidden layers\n",
    "    for i in range(1,lyrs):\n",
    "        model.add(Dense(neuron_size, activation=act))\n",
    "        model.add(Dropout(dr))\n",
    "        \n",
    "    model.add(Dense(neuron_size, activation='softmax'))    \n",
    "        #tf.keras.layers.BatchNormalization(),\n",
    "    # add dropout, default is none\n",
    "    #model.add(Dropout(dr))\n",
    "    \n",
    "    # create output layer\n",
    "    model.add(Dense(18, activation='sigmoid'))  # output layer\n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    huber = tf.keras.losses.Huber(delta=1.5)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mse', 'mape','mae',tf.keras.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f10652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrics_plot(history,train_matrics,val_matrics,lable_name,model_name, data_of,plot_path):\n",
    "    import matplotlib.ticker as tck\n",
    "    all_train_mae_histories = []\n",
    "    train_mae_history = train_matrics\n",
    "    all_train_mae_histories.append(train_mae_history)\n",
    "    average_train_mae_history = [\n",
    "        np.mean([x[i] for x in all_train_mae_histories]) for i in range(max_epochs)]\n",
    "\n",
    "    all_val_mae_histories = []\n",
    "    val_mae_history = val_matrics\n",
    "    all_val_mae_histories.append(val_mae_history)\n",
    "    average_val_mae_history = [\n",
    "        np.mean([x[i] for x in all_val_mae_histories]) for i in range(max_epochs)]\n",
    "    \n",
    "    loss = train_matrics\n",
    "    val_loss = val_matrics\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, 'b', linewidth=2, label='Training '+lable_name)\n",
    "    plt.plot(epochs, val_loss, '--r',  linewidth=1, label='Validation '+lable_name)\n",
    "    plt.title('Training and Validation '+lable_name)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(lable_name)\n",
    "    plt.legend()\n",
    "    #plt.savefig('mae_hardness.pdf',dpi=1200)\n",
    "    plt.show()\n",
    "    \n",
    "    def smooth_curve(points, factor=0.9):\n",
    "      smoothed_points = []\n",
    "      for point in points:\n",
    "        if smoothed_points:\n",
    "          previous = smoothed_points[-1]\n",
    "          smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "          smoothed_points.append(point)\n",
    "      return smoothed_points\n",
    "\n",
    "    smooth_train_mae_history = smooth_curve(average_train_mae_history[5:])\n",
    "    smooth_val_mae_history = smooth_curve(average_val_mae_history[5:])\n",
    "    \n",
    "    sns.set(style=\"ticks\", color_codes=True,font_scale=2.25)\n",
    "    fig, ax = plt.subplots(figsize=(6,5.5),dpi=600)\n",
    "    #plt.ylim(20, 120)    # y-label range\n",
    "    plt.gca().yaxis.set_minor_locator(tck.AutoMinorLocator(2))\n",
    "    plt.plot(range(1, len(smooth_train_mae_history) + 1), smooth_train_mae_history, 'b', label = 'Training '+lable_name)\n",
    "    plt.plot(range(1, len(smooth_val_mae_history) + 1),smooth_val_mae_history, '--r', label = 'Validation '+lable_name)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(''+lable_name)\n",
    "    #plt.title('Smooth Training and Validation '+lable_name)\n",
    "    plt.title(data_of+': '+model_name)\n",
    "    plt.legend()\n",
    "    plt.savefig(plot_path+data_of+'_'+lable_name+'.pdf',dpi=1200, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5c06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict on test data\n",
    "\n",
    "def r2_plot(model,input_datasets,target_datasets,name,model_name,plot_path=\"plots\\\\hardness\\\\_\"):\n",
    "    sns.set(style=\"ticks\", color_codes=True,font_scale=1.25)\n",
    "    a=0.2 # Percentage error range\n",
    "    predictions_datasets = model.predict(input_datasets)\n",
    "\n",
    "    import sklearn.metrics\n",
    "    from sklearn.metrics import r2_score\n",
    "    r2_test = r2_score(target_datasets, predictions_datasets)\n",
    "    plt.figure(figsize=(4,4),dpi=200)\n",
    "\n",
    "    # plot x=y line \n",
    "    x_line = np.linspace(0, 50, 50)\n",
    "    \n",
    "    sns.lineplot(x=x_line, y=x_line,color='black',lw=0.75)\n",
    "\n",
    "    print('Test R2 score: ', r2_test)\n",
    "    \n",
    "\n",
    "\n",
    "    test_r2 = sns.regplot(x=target_datasets,y=predictions_datasets,ci=None,scatter_kws=dict(s=8,color='r'),fit_reg=False)\n",
    "    test_r2.set(title=str(model_name)+'Performance on Test data,'+' $R^2$ = ' +str(round(r2_test,3)))\n",
    "    test_r2.set_xlabel(\"Real Targets\"+\"(\"+name+\")\", fontsize = 16)\n",
    "    test_r2.set_ylabel(\"Predicted Value\"+\"(\"+name+\")\", fontsize = 16)\n",
    "\n",
    "    Y1 = x_line*(1+a)\n",
    "    Y2 = x_line*(1-a)\n",
    "\n",
    "    sns.lineplot(x=x_line,y=Y1,lw=0.5,color='b',alpha=.2)\n",
    "    sns.lineplot(x=x_line,y=Y2,lw=0.5,color='b',alpha=.2)\n",
    "\n",
    "    test_r2.fill_between(x_line, Y1,x_line,color='b',alpha=.2)\n",
    "    test_r2.fill_between(x_line, Y2,x_line,color='b',alpha=.2)\n",
    "    \n",
    "    # x and y ticks\n",
    "    listOf_Yticks = np.arange(0, 40, 5)\n",
    "    plt.yticks(listOf_Yticks)\n",
    "    plt.xticks(listOf_Yticks)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #ax.yaxis.set_minor_locator(tck.AutoMinorLocator(2))\n",
    "\n",
    "\n",
    "    test_r2.figure.savefig('r2_hardness_'+str(name)+'.png',dpi=1200, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
